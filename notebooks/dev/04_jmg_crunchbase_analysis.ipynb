{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrunchBase analysis\n",
    "\n",
    "Here we load the CB data that we processed before and report emerging findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cb(file,file_path,progress=True):\n",
    "    \"\"\" Fetch Gateway To Research predicted industries\n",
    "\n",
    "    Repo: https://github.com/nestauk/gtr_data_processing\n",
    "    Commit: cd3cddb\n",
    "    File: https://github.com/nestauk/gtr_data_processing/blob/master/notebooks/05_jmg_data_demo.ipynb\n",
    "\n",
    "    Args:\n",
    "        file_path (`str`, optional): Path to download to. If None, stream file.\n",
    "        progress (`bool`, optional): If `True` and `file_path` is not `None`,\n",
    "            display download progress.\n",
    "    \"\"\"\n",
    "    \n",
    "    return download_file(file_to_fetch=file, download_path=file_path+file, progress=progress)\n",
    "\n",
    "def get_example(df,number,length,var='long_description'):\n",
    "    '''\n",
    "    Gets random examples in a field\n",
    "    \n",
    "    Args:\n",
    "        Df is the dataframe we want to use\n",
    "        number is the number of examples we want\n",
    "        length is the length of the examples\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    choose = random.sample(list(df.index),number)\n",
    "    \n",
    "    for x in df.loc[choose][var]:\n",
    "        \n",
    "        print(x[:length])\n",
    "        print('\\n')\n",
    "        \n",
    "def create_lq(X, binary=False):\n",
    "    \"\"\" Calculate the location quotient.\n",
    "\n",
    "    Divides the share of activity in a location by the share of activity in the UK total\n",
    "\n",
    "    Args:\n",
    "        X (pandas.DataFrame): DataFrame where rows are locations, columns are sectors and values are activity in a given sector at a location.\n",
    "        binary (bool, optional): If True, discretise the data with a cut-off value of 1\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame\n",
    "    \"\"\"\n",
    "    Xm = X.values\n",
    "    X = pd.DataFrame((Xm/Xm.sum(1)[:, np.newaxis])/(Xm.sum(0)/Xm.sum()),\n",
    "            index=X.index, columns=X.columns)\n",
    "    \n",
    "    return (X > 1) if binary else X\n",
    "\n",
    "def flat_freqs(a_list):\n",
    "    '''\n",
    "    Gets elxement frequencies in a nested list\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return(pd.Series(flatten(a_list)).value_counts())\n",
    "\n",
    "def flatten(a_list):\n",
    "    '''\n",
    "    Flattens a list\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    return([x for el in a_list for x in el])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = pd.read_csv('../../data/processed/20_9_2019_cb_fnf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read CB funding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config = '../../../mysqldb_team.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_getters.core import get_engine\n",
    "\n",
    "con = get_engine(my_config)\n",
    "funding_rounds = pd.read_sql_table('crunchbase_funding_rounds', con, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_fr_df = pd.concat(funding_rounds).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_fr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_fr_df['company_name'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm that this is capturing round-company pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing of funding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_fr_df['year'] = [x.year for x in cb_fr_df['announced_on']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse investor names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#They are sets, sometimes malformed\n",
    "#We parse them hackily by removing leading and trailing '{}' etc\n",
    "cb_fr_df['investor_names_list'] = [re.sub('\"','',str(x[1:-1])).split(',') if x!='{}' else np.nan for x in cb_fr_df['investor_names']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity and funding trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['lightcoral','red','darkorchid','deepskyblue','blue','cadetblue']\n",
    "sectors = ['artificial_intelligence','advertising','creative_content','news_high','public_news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trends(df_act,df_fund,sectors,colors,thres=0.75):\n",
    "    '''\n",
    "    Various plots comparing evolution of activity in different sectors\n",
    "    \n",
    "    Args:\n",
    "        df contains the company data and df fund the funding data\n",
    "        sectors is sectors\n",
    "        colors is colors\n",
    "        thres is the threshold for considering a company in a sector (defaults to 0.75)\n",
    "    \n",
    "    Will save the plots and return the source dfs\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    output = {}\n",
    "    \n",
    "    #######\n",
    "    #Activity plot\n",
    "    #######\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(12,7),nrows=2,sharex=True,gridspec_kw={'height_ratios':[3,1]})\n",
    "    \n",
    "    #First plot component (activity in a sector as a share of the total)\n",
    "    \n",
    "    #This stores the year shares\n",
    "    year_shares = []\n",
    "    \n",
    "    for n,s in enumerate(sectors):\n",
    "        sh = (100*pd.crosstab(df_act['year'],df_act[s]>thres,normalize=0)).loc[np.arange(2000,2019)][True]\n",
    "    \n",
    "        sh.rolling(window=3).mean().dropna().plot(ax=ax[0],color=colors[n],linewidth=3 if 'news' in s else 1)\n",
    "\n",
    "        year_shares.append(sh)\n",
    "    \n",
    "    #Axes\n",
    "    ax[0].set_ylabel('% of all companies')\n",
    "    ax[0].legend(sectors,bbox_to_anchor=(1,1))\n",
    "\n",
    "    year_shares_df = pd.concat(year_shares,axis=1)\n",
    "    year_shares_df.columns = sectors\n",
    "    \n",
    "    output['year_shares'] = year_shares_df\n",
    "    \n",
    "    #Add the second figure with news as a share of the total \n",
    "    \n",
    "    news = df_act.loc[cb['news_high']==True]\n",
    "    \n",
    "    news_shares = (100*pd.crosstab(news['year'],news['public_news']>thres,normalize=0)).loc[np.arange(2000,2019)][True]\n",
    "    news_shares.name = 'pin_share_of_news'\n",
    "    \n",
    "    news_shares.rolling(window=3).mean().dropna().plot(\n",
    "        ax=ax[1],color='blue',linewidth=3)\n",
    "    \n",
    "    ax[1].set_ylabel('% of all \\n news companies')\n",
    "    \n",
    "    output['pin_share_of_news'] = news_shares\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('../../reports/figures/research_slides/cb/activity_trends.pdf')\n",
    "    \n",
    "    \n",
    "    #########\n",
    "    #Funding plot\n",
    "    #########\n",
    "    \n",
    "    df_fund_2 = df_fund.copy()\n",
    "    \n",
    "    #This identifies IDs\n",
    "    rel_sets = [set(df_act.loc[df_act[s]>thres]['id']) for s in sectors]\n",
    "    \n",
    "    for s,s_set in zip(sectors,rel_sets):\n",
    "        \n",
    "        df_fund_2[s] = [x in s_set for x in df_fund_2['company_id']]\n",
    "        \n",
    "        \n",
    "    fig,ax = plt.subplots(figsize=(12,7),nrows=2,sharex=True,gridspec_kw={'height_ratios':[3,1]})\n",
    "\n",
    "    #This is calculating totals raised per sector\n",
    "    total_raised = pd.concat([df_fund_2.loc[df_fund_2[s]==True].groupby('year')['raised_amount_usd'].sum() for s in sectors],axis=1).fillna(0).loc[\n",
    "        np.arange(2000,2019)]/1e9\n",
    "\n",
    "    total_raised.columns = sectors\n",
    "    \n",
    "    total_raised.rolling(window=3).mean().dropna().plot(color=colors,ax=ax[0])\n",
    "\n",
    "    ax[0].set_ylabel('$ Billion')\n",
    "    \n",
    "    #Store total raised  \n",
    "    output['total_raised'] = total_raised\n",
    "    \n",
    "\n",
    "    #Now calculate funding raised by news as a share of the total\n",
    "    \n",
    "    news_funding= df_fund_2.loc[df_fund_2['news']==True]\n",
    "\n",
    "    news_share_funding = (100*news_funding.groupby(['year','pi_news'])['raised_amount_usd'].sum().reset_index(drop=False).pivot(\n",
    "        index='year',columns='pi_news',values='raised_amount_usd').apply(lambda x: x/x.sum(),axis=1).loc[np.arange(2000,2019)].fillna(0))\n",
    "                  \n",
    "    news_share_funding.rolling(window=3).mean().dropna()[True].plot(color='blue',ax=ax[1],linewidth=3)\n",
    "\n",
    "    ax[1].set_ylabel('PI news as \\n  % of all news')\n",
    "    \n",
    "    output['pin_shares_of_news_funding'] = news_share_funding\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('../../reports/figures/research_slides/cb/funding_trends.pdf')\n",
    "\n",
    "    return(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_outputs = make_trends(cb,cb_fr_df,sectors,colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What explains the surge in news funding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_sets = [set(cb.loc[cb[s]>0.75]['id']) for s in ['news_high','public_news']]\n",
    "\n",
    "cb_fr_df['news'],cb_fr_df['pin'] = [[x in s_set for x in cb_fr_df['company_id']] for s_set in rel_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This thing compares geographical activity before and after 2015\n",
    "ax = cb_fr_df.loc[(cb_fr_df['news']==True)].assign(threshold=cb_fr_df['year']>2015).groupby([\n",
    "    'country','threshold'])['raised_amount_usd'].sum().reset_index(drop=False).pivot(index='country',columns='threshold',\n",
    "                                                                                     values='raised_amount_usd').sort_values(\n",
    "    True,ascending=False)[:10].plot.bar()\n",
    "\n",
    "ax.legend(['Before 2015','After 2015'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_outputs['total_raised'].loc[2018]*1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situation in the UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_new_sets = [set(cb.loc[(cb[s]>0.75)&(cb['country_alpha_2']=='GB')]['id']) for s in ['news_high','public_news']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_fr_df['uk_news'],cb_fr_df['uk_pi_news'] = [[x in one_set for x in cb_fr_df['company_id']] for one_set in uk_new_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([cb_fr_df.groupby(var)['raised_amount_usd'].sum()[True] for var in ['uk_news','uk_pi_news']],\n",
    "            index=['All News','Public Interest'],columns=['Total raised USD'])/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key investors in public interest news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = flat_freqs(cb_fr_df.loc[cb_fr_df['pi_news']==True,'investor_names_list'].dropna()).head(n=20)[::-1].plot.barh(color='blue',figsize=(8,8))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../../reports/figures/research_slides/cb/top_funders.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most UK deals the investor data is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of investment in public news globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pi_finance_comp = pd.crosstab(cb_fr_df['investment_type'],cb_fr_df['pi_news'],normalize=1).sort_values(True,ascending=False)\n",
    "\n",
    "\n",
    "finance_uk = cb_fr_df.loc[cb_fr_df['country']=='United Kingdom']\n",
    "uk_pi_finance_comp = pd.crosstab(finance_uk['investment_type'],finance_uk['pi_news'],normalize=1)\n",
    "\n",
    "\n",
    "pi_finance_global_uk = pd.concat([all_pi_finance_comp[True],uk_pi_finance_comp[True],all_pi_finance_comp[False]],axis=1).fillna(0)\n",
    "\n",
    "pi_finance_global_uk.columns = ['Global','UK','Non-PIN']\n",
    "\n",
    "pi_finance_global_uk = pi_finance_global_uk.sort_values('UK',ascending=True)[['UK','Global','Non-PIN']]\n",
    "\n",
    "ax = pi_finance_global_uk.plot.barh(figsize=(8,10),color=['blue','coral','white'],edgecolor='black')\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_xlabel('% of all funding')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../../reports/figures/research_slides/cb/funding_modalities.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,9),nrows=2,sharex=True)\n",
    "\n",
    "pd.crosstab(cb['country'],cb['public_news']).sort_values(True,ascending=False)[:10][True].plot.bar(ax=ax[0],color='blue')\n",
    "\n",
    "ax[0].set_ylabel('Total number of \\n PIN companies')\n",
    "\n",
    "create_lq(pd.crosstab(cb['country'],cb['public_news']).sort_values(True,ascending=False))[:10][True].plot.bar(ax=ax[1],color='blue')\n",
    "\n",
    "ax[1].hlines(y=1,xmin=-0.5,xmax=25,linestyle=':',color='red',linewidth=3)\n",
    "ax[1].set_ylabel('Specialisation in \\n PIN')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../../reports/figures/research_slides/cb/country_activity.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_pin = pd.crosstab(cb['country'],cb['public_news']).loc['United Kingdom']\n",
    "\n",
    "100*uk_pin[True]/uk_pin.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(cb.loc[(cb['country']=='Netherlands')&(cb['public_news']==True)],5,600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geography in the UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_comps = cb.loc[(cb['country_alpha_2']=='GB')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_example(uk_comps.loc[uk_comps['public_news']==True],4,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(uk_comps['lad18nm'],uk_comps['public_news'],normalize=1).sort_values(True,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector crossover\n",
    "\n",
    "Now we check what % of companies in news have overlaps with other sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_sectors = cb['sector_dom'].value_counts().index[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sector_crossover(df,sectors,cb_sectors,normalise=True,thres=[0.75,0.3]):\n",
    "    '''\n",
    "    This outputs the % of companies in a sector overlapping with another sector\n",
    "    \n",
    "    Args:\n",
    "        df is the activity df\n",
    "        sectors is the sectors whose overlaps we want to study\n",
    "        cb_sectors are all the cb_sectors that could overlap with a focus sectors\n",
    "        normalise if we want to get the % of companies in sector overlapping\n",
    "        threshold is the threshold for considering a company in a sector\n",
    "    '''\n",
    "    \n",
    "    crossovers = []\n",
    "    \n",
    "    for s in sectors:\n",
    "        sector_crossover = pd.Series([len(df[(df[s]>thres[0])&(df[cb_s]>thres[1])]) for cb_s in cb_sectors],index=cb_sectors)\n",
    "        \n",
    "        #print(sector_crossover)\n",
    "        \n",
    "        if normalise==True:\n",
    "            sector_crossover = sector_crossover/len(df.loc[df[s]>thres[0]])\n",
    "    \n",
    "        crossovers.append(sector_crossover)\n",
    "        \n",
    "    crossover_df = pd.concat(crossovers,axis=1)\n",
    "    crossover_df.columns = sectors\n",
    "    \n",
    "    \n",
    "    return(crossover_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = ['news_high','public_news']\n",
    "\n",
    "cross = sector_crossover(cb,sectors,cb_sectors.drop('publishing_news'),normalise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,2))\n",
    "\n",
    "sns.heatmap(cross.sort_values('public_news',ascending=False).T.iloc[:,:20],ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
